{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM example\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense,Dropout,Activation,BatchNormalization, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train = pd.read_csv(\"C:\\\\Users\\\\suneelnair1\\\\Documents\\\\Sunil\\\\Class_notes\\\\Research_Internship\\\\LSTM_program\\\\labeledTrainData.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test = pd.read_csv(\"C:\\\\Users\\\\suneelnair1\\\\Documents\\\\Sunil\\\\Class_notes\\\\Research_Internship\\\\LSTM_program\\\\testData.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import csv\n",
    "\n",
    "#datafile = open('C:\\\\Users\\\\suneelnair1\\\\Documents\\\\Sunil\\\\Class_notes\\\\Research_Internship\\\\LSTM_program\\\\labeledTrainData.csv',encoding='utf8')\n",
    "#datareader = csv.reader(datafile)\n",
    "\n",
    "#train=[]\n",
    "\n",
    "#for row in datareader:\n",
    "#    train.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = train\n",
    "#Y_train = np.genfromtxt('C:\\\\Users\\\\suneelnair1\\\\Documents\\\\Sunil\\\\Class_notes\\\\Research_Internship\\\\LSTM_program\\\\labels.csv',dtype='int',delimiter='\\t')\n",
    "#Y_test = np.genfromtxt('C:\\\\Users\\\\suneelnair1\\\\Documents\\\\Sunil\\\\Class_notes\\\\Research_Internship\\\\LSTM_program\\\\labels_test.csv',dtype='int',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17432576/17464789 [============================>.] - ETA: 0s25000 Train sequences\n",
      "25000 Test sequences\n",
      "Pad sequences (samples x time)\n",
      "x train shape (25000, 80)\n",
      "x test shape (25000, 80)\n",
      "(17494, 106)\n",
      "(7498, 95)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "\n",
    "(x_train,y_train), (x_test,y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "print(len(x_train), 'Train sequences')\n",
    "print(len(x_test), 'Test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train,maxlen = maxlen)\n",
    "x_test = sequence.pad_sequences(x_test,maxlen = maxlen)\n",
    "\n",
    "print('x train shape',x_train.shape)\n",
    "print('x test shape',x_test.shape)\n",
    "\n",
    "Y_train=np_utils.to_categorical(Y_train,nb_classes)\n",
    "Y_test=np_utils.to_categorical(Y_test,nb_classes)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model..\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train the model...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 224s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 215s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 218s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 217s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 215s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 222s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 213s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 224s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 219s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 218s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 222s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 219s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 221s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 217s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 224s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "24992/25000 [============================>.] - ETA: 0sTest Score:  7.97119235672\n",
      "Test Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Create the LSTM model\n",
    "\n",
    "print('Building the model..')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,128))\n",
    "model.add(LSTM(128,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "print('Train the model...')\n",
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=15,validation_data=(x_test,y_test))\n",
    "\n",
    "score,acc = model.evaluate(x_test,y_test,batch_size=batch_size)\n",
    "\n",
    "print('\\nTest Score: ', score)\n",
    "print('\\nTest Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
